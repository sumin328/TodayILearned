# ADsP / 3-5. 정형 데이터 마이닝

Created By: 수민 오
Last Edited: Nov 25, 2019 3:18 PM
Tags: ADsP, 노트정리

### 데이터마이닝의 개요

- 데이터 마이닝
    - 대용량 데이터에서 의미있는 패턴을 파악하거나 예측하여 의사결정에 활용하는 방법
    - 통계분석은 가설이나 가정에 따른 분석이나 검증을 하지만 데이터마이닝은 다양한 수리 알고리즘을 이용해 데이터베이스의 데이터로부터 의미있는 정보를 찾아내는 방법을 통칭함
    - 정보를 찾는 방법론에 따른 종류
        - 인공지능
        - 의사결정나무
        - K-평균군집화 (K-means Clustering)
        - 연관분석
        - 회귀분석
        - 로짓분석
        - 최근접이웃
    - 분석대상, 활용목적, 표현방법에 따른 분류
        - 시각화분석(Visualization Analysis)
        - 분류(Classification)
        - 군집화(Clustering)
        - 포케스팅(Forecasting)
    - 분석방법 - 지도학습
        - 의사결정나무
        - 인공신경망
        - 일반화 선형 모형
        - 회귀분석
        - 로지스틱 회귀분석
        - 사례기반 추론
        - 최근접 이웃법
    - 분석방법 - 비지도학습
        - 자료가 출력변수 없이 입력변수만 주어진 경우, 입력변수들간의 상호관계나 입력 자료값들 간의 관계를 탐색적으로 분석할 때 사용
        - OLAP (On-Line Analytical Processing)
        - 연관성 규칙발견
        - 군집분석
        - SOM(Self Organizing Map)
- 분석 목적에 따른 작업 유형과 기법
    - 예측
        - 분류규칙(Classification)
            - 가장 많이 사용되는 작업으로 과거의 데이터로부터 고객특성을 찾아내어 분류모형을 만들어 이를 토대로 새로운 레코드의 결과값을 예측하는 것으로 목표 마케팅 및 고객 신용평가 모형에 활용됨
            - 회귀분석, 판별분석, 신경망, 의사결정나무
    - 설명
        - 연관규칙(Association)
            - 데이터 안에 존재하는 항목간의 종속관계를 찾아내는 작업
            - 동시발생 매트릭스
        - 연속규칙(Sequence)
            - 연관 규칙에 시간관련 정보가 포함된 형태
            - 동시발생 매트릭스
        - 데이터 군집화(Clustering)
            - 고객 레코드들을 유사한 특성을 지닌 몇 개의 소그룹으로 분할하는 잡업으로 작업의 특성이 분류규칙과 유사하나 분석대상 데이터에 결과값이 없음
            - K-Means Clustering
- 데이터마이닝 추진단계
    - 목적 설정
    - 데이터 준비
    - 가공
    - 기법 적용
    - 검증
- 데이터마이닝을 위한 데이터 분할
    - 개요 - 모델 평가용 테스트 데이터와 구축용 데이터로 분할하여, 구축용 데이터로 모형을 생성하고 테스트 데이터로 모형이 얼마나 적합한지를 판단
    - 구축용(training data, 50%)
    - 검정용(validation data, 30%)
    - 시험용(test data, 20%)
    - 데이터의 양이 충분하지 않거나 입력 변수에 대한 설명이 충분한 경우
        - 홀드아웃 방법 : 주어진 데이터를 랜덤하게 두 개의 데이터로 구분하여 사용하는 방법으로 주로 학습용과 시험용으로 분리하여 사용
        - 교차확인 방법 : 주어진 데이터를 k개의 하부집단으로 구분하여, k-1개의 집단을 학습용으로 나머지 하부집단으로 검증용으로 설정하여 학습, k번 반복 측정한 결과를 평균낸 값을 최종값으로 사용
- 성과분석
    - 오분류에 대한 추정치
        - 정분류율, 정확도 (Accuracy) = (TN + TP) / (TN + TP + FN + FP)
        - 오분류율(Error Rate) = 1 - Accuracy = (FN + FP) / (TN + TP + FN + FP)
        - 특이도 (Specificity) = TN / (TN + FP)
        - 민감도 (Sensitivity) = TP / (TP + FN)
        - 정확도 (Precision) = TP / (TP + FP)
        - 재현율( Recall) = Sensitivity = TP / (TP + FN)
        - F1 Score = (2 * Precision * Recall) / (Precision + Recall)
        1. AR = (TP + TN) 
        2. 모두 부정일 경우 정확도가 높아도 의미가 없음
        3. 이것을 보완하는 방법은 민감도와 특이도이다. 모두 좋아야 좋은 모형으로 볼 수 있다.
    - ROCR 패키지로 성과분석
        - ROC Curve(Receiver Operating Characteristic Curve)
        - 가로축을 FPR(1-특이도)로, 세로축을 TPR(민감도)로 두어 시각화한 그래프
        - 왼쪽 상단에 가깝게 그려질수록 올바르게 예측한 비율은 높고, 잘못 예측한 비율은 낮음을 의미함
        - ROC곡선 아래의 면적을 의미하는 AUROC값이 클수록(1에 가까울수록) 모형의 성능이 좋다고 평가
    - 이익도표
        - 분류된 관측치에 대해 얼마나 예측이 잘 이루어졌는지를 나타내기 위해 임의로 나눈 각 등급별로 반응검출율, 반응률, 리프트 등의 정보를 산출하여 나타내는 도표

### 분류분석

- 분류분석과 예측분석
    - 분류분석
        - 테이터가 어떤 그룹에 속하는지 예측하는데 사용되는 기법
        - 클러스터링과 유사하지만, 분류분석은 각 그룹이 정의되어 있음
        - 교사합습에 해당하는 예측기법
        - ex. 내신등급, 신용등급...
    - 예측분석
        - 시계열분석처럼 시간에 따른 값 두 개만을 이용해 앞으로의 매출 또는 온도 등을 예측하는 것
        - 모델링을 하는 입력 데이터가 어떤 것인지에 따라 특성이 다름
        - 여러 개의 다양한 설명변수가 아닌, 한 개의 설명변수로 생각
        - ex. 수능점수 예측, 매출액 예측
    - 공통점과 차이점
        - 공통점 - 레코드의 특정 속성의 값을 미리 알아맞힘
        - 차이점
            - 분류 : 레코드의 범주형 속성의 값을 알아맞히는 것
            - 예측 : 레코드의 연속형 속성의 값을 알아맞히는 것
    - 분류 모델링
        - 신용평가모형 (우량, 불량)
        - 사기방지모형 (사기, 정상)
        - 이탈모형 (이탈, 유지)
        - 고객세분화
    - 분류기법
        - 회귀분석, 로지스틱 회귀분석
        - 의사결정나무, CART, C5.0
        - 베이지안 분류, Naive Bayesian
        - 인공신경망
        - 지지도벡터기계
        - k최근접 이웃
        - 규칙기반의 분류와 사례기반추론
- 로지스틱 회귀분석
    - 반응변수가 범주형인 경우에 적용되는 회귀분석모형
    - 새로운 설명변수가 주어질 때 반응변수의 각 범주에 속할 확률이 얼마인지 추정(예측모형)하여, 추정 확률을 기준치에 따라 분류하는 목적(분류모형)으로 활용
    - 모형의 적합을 통해 추정된 확률을 사후확률이라고 함
- 의사결정나무
    - 분류함수를 의사결정 규칙으로 이뤄진 나무 모양으로 그리는 방법
    - 입력값에 대하여 출력값을 예측하는 모형으로 분류나무와 회귀나무 모형이 있음
    - 활용
        - 세분화 - 데이터를 비슷한 특성을 갖는 몇 개의 그룹으로 분할해 그룹별 특성을 발견하는 것
        - 분류 - 여러 예측변수들에 근거해 관측개체의 목표변수 범주를 몇 개의 등급으로 분류
        - 예측 - 자료에서 규칙을 찾아내고 이를 이용해 미래의 사건을 예측
        - 차원축소 및 변수선택 - 매우 많은 수의 예측변수 중에서 목표변수에 큰 영향을 미치는 변수들을 골라내고자 하는 경우에 사용
        - 교호작용효과의 파악 - 여러 개의 예측변수들을 결합해 목표변수에 작용하는 규칙을 파악하고자 하는 경우
        - 범주의 병합 또는 연속형 변수의 이산화 - 범주형 목표변수의 범주를 소수의 몇 개로 병합하거나 연속형 목표변수를 몇 개의 등급으로 이산화 하고자 하는 경우
    - 특징
        - 장점
            - 결과를 누구에게나 설명하기 용이
            - 모형을 만드는 방법이 계산적으로 복잡하지 않음
            - 대용량 데이터에서도 빠르게 만들 수 있음
            - 비정상 잡음 데이터에 대해서 민감함 없이 분류할 수 있음
            - 한 변수와 상관성이 높은 다른 불필요한 변수가 있어도 크게 영향을 받지 않음
            - 설명변수나 목표변수에 수치형변수와 범주형 변수를 모두 사용 가능함
            - 모형 분류 정확도가 높음
        - 단점
            - 새로운 자료에 대한 과대적합이 발생할 가능성이 높음
            - 분류 경계선 부근의 자료값에 대해서 오차가 큼
            - 설명변수 간의 중요도를 판단하기 쉽지 않음

    - 분석과정
        1. 성장 
            - 각 마디에서 적절한 최적의 분리규칙을 찾아 나무를 성장 / 적절한 정지규칙을 만족하면 중단
            - 분리규칙 - 최적 분할의 결정은 분순도 감소량을 가장 크게 하는 분할
            - 분리기준 (이산형) - 카이제곱 통계량 p값 / 지니 지수 / 엔트로피 지수
            - 분리기준 (연속형) - 분산분석에서 F 통계량 / 분산의 감소량
            - 정지규칙
                - 더 이상 분리가 일어나지 않고, 현재의 마디가 끝마디가 되도록 하는 규칙
                - 정지기준 : 의사결정나무의 깊이 (depth)를 지정, 끝마디의 레코드 수의 최소 개수를 지정
        2. 가지치기
            - 오차를 크게 할 위험이 높거나 부적절한 추론규칙을 가지고 있는 가지 또는 불필요한 가지를 제거
            - 너무 큰 나무모형은 과대적합, 너무 작은 나무모형은 과소적합할 위험이 있음
            - 자료가 일정 수 이하일 때 분할을 정지하고 비용-복잡도 가지치기를 이용하여 가지치기함
        3. 타당성 평가 
            - 이익도표, 위험도표, 혹은 시험자료를 이용하여 의사결정나무를 평가
        4. 해석 및 예측 
            - 구축된 나무모형을 해석하고 예측모형을 설정한 후 예측에 적용
- 불순도의 여러 가지 측도
    - 카이제곱 통계량
    - 지니지수
        - 노드의 불순도를 나타내는 값
        - 지니지수의 값이 클수록 이질적이며 순수도가 낮다고 볼 수 있음
    - 엔트로피 지수
        - 열역학에서 쓰는 개념으로 무질서 정도에 대한 추측
        - 엔트로피 지수의 값이 클수록 순수도가 낮다고 볼 수 있음
        - 엔트로피 지수가 가장 작은 예측 변수와 이떄의 최적분리 규칙에 의해 자식마디를 형성
- 의사결정나무 알고리즘
    - CART (Classification and Regression Tree)
        - 출력변수가 범주형일 경우 지니지수를, 연속형인 경우 분산을 이용한 이진분리를 사용
    - C4.5와 C5.0
        - CART와는 다르게 각 마디에서 다지분리가 가능하며 범주형 입력변수에 대해서는 범주의 수만큼 분리가 일어남
        - 불순도의 측도로는 엔트로피지수를 사용
    - CHAID
        - 가지치기를 하지 않고 적당한 크기에서 나무모형의 성장을 중지하며 입력변수가 반드시 범주형 변수여야 함
        - 불순도의 측도로는 카이제곱 통계량을 사용

### 앙상블 분석

- 앙상블
    - 주어진 자료로부터 여러 개의 예측모형들을 만든 후 예측모형들을 조합하여 하나의 최종 예측모형을 만드는 방법으로 다중 모델 조합, 분류기 조합이 있다.
    - 학습방법의 불안전성
        - 학습자료의 작은 변화에 의해 예측모형이 크게 변하는 경우, 그 학습방법은 불안정하다.
        - 가장 안정적인 방법 - 1-nearest neighbor, 선형회귀모형
        - 가장 불안정한 방법 - 의사결정나무
- 앙상블 기법의 종류
    - 배깅
        - 붓스트랩(Bootstrap) - 주어진 자료에서 동일한 크기의 표본을 랜덤 복원추출로 뽑은 자료를 의미
        - 여러 개의 붓스트랩 자료를 생성하고 각 붓스트랩 자료에 예측모형을 만든 후 결합하여 최종 예측모형을 만드는 방법
        - 보팅(Voting) - 여러 개의 모형으로부터 산출된 결과를 다수결에 의해서 최종 결과를 선정하는 과정
        - 배깅에서는 가지치기를 하지 않고 최대한 성장한 의사결정나무들을 활용
        - 훈련자료를 모집단으로 생각하고 평균예측모형을 구하여 분산을 줄이고 예측력을 향상시킬 수 있음
    - 부스팅
        - 예측력이 약한 모형들을 결합하여 강한 예측모형을 만드는 방법
        - Adaboost - 이진분류 문제에서 랜덤 분류기보다 조금 더 좋은 분류기 n개에 각각 가중치를 설정하고 n개의 분류기를 결합하여 최종 분류기를 만드는 방법
        - 훈련오차를 빨리 그리고 쉽게 줄일 수 있다
        - 배깅에 비해 많은 경우 예측오차가 향상되어 Adaboost의 성능이 배깅보다 뛰어난 경우가 많다
    - 랜덤 포레스트
        - 배깅과 부스팅보다 더 많은 무작위성을 주어 약한 학습기들을 생성한 후 이를 선형 결합하여 최종 학습기를 만드는 방법
        - 정확도 측면에서 좋은 성과를 보임
        - 해석이 어렵다는 단점이 있지만 예측력이 매우 높은 것으로 알려져 있음
        - 특히 입력변수가 많은 경우, 배깅과 부스팅과 비슷하거나 좋은 예측력을 보임

### 인공신경망 분석

- 인공신경망 분석
    - 인간 뇌를 기반으로 한 추론 모델
    - 뉴런은 기본적인 정보처리 단위
    - 역전파알고리즘을 활용하여 비선형성을 극복한 다계층 퍼셉트론으로 새로운 인공신경망 모형이 등장
- 인공신경망의 학습
    - 가중치를 반복적으로 조정하며 학습
    - 뉴런은 링크로 연결되어 있고, 각 링크에는 수치적인 가중치가 있다
    - 인공 신경망은 신경망의 가중치를 초기화하고 훈련 데이터를 통해 가중치를 갱신하여 신경망의 구조를 선택하고, 활용할 학습 알고리즘을 결정한 후 신경망을 훈련시킨다
- 특징
    - 구조
        - 입력 링크에서 여러 신호를 받아 새로운 활성화 수준을 계산, 출력 링크로 출력 신호를 보냄
        - 입력신호는 미가공 데이터 또는 다른 뉴런의 출력이 될 수 있음
        - 출력신호는 문제의 최종적인 해가 되거나 다른 뉴런에 입력 될 수 있음
    - 계산
        - 뉴런은 전이함수, 즉 활성화 함수를 사용
        - 활성화 함수를 이용해 출력을 결정하며 입력신호의 가중치 합을 계산하여 임계값과 비교
        - 가중치 합이 임계값보다 작으면 뉴럽의 출력은 -1, 같거나 크면 +1을 출력
    - 뉴런의 활성화 함수
        - 시그모이드 함수의 경우 로지스틱 회귀분석과 유사, 0~1의 확률값을 가짐
        - softmax함수 : 표준화지수 함수로도 불리며, 출력값이 여러개로 주어지고 목표치가 다범주인 경우 각 범주에 속할 사후확률을 제공하는 함수
        - Relu함수 : 입력값이 0이하는 0, 0이상은 x값을 가지는 함수
    - 단일 뉴런의 학습 (단층 퍼셉트론)
        - 퍼셉트론은 선형 결합기와 하드 리미터로 구성됨
        - 초평면은 n차원 공간을 두개의 영역으로 나눔
        - 초평면을 선형 분리 함수로 정의
- 신경망 모형 구축시 고려사항
    - 입력 변수
        - 신경망 모형은 복잡성으로 인하여 입력 자료의 선택에 매우 민감함
        - 입력변수가 범주형 또는 연속형 변수일 때 아래의 조건이 신경망 모형에 적합함
            - 범주형 - 모든 범주에서 일정 빈도 이상의 값을 갖고 각 범주의 빈도가 일정할 떄
            - 연속형 - 입력변수 값들의 범위가 변수간의 큰 차이가 없을 때
        - 연속형 변수의 경우 그 분포가 평균을 중심으로 대칭이 아니면 좋지 않은 결과를 도출하기 때문에 아래와 같은 방법을 활용함
            - 변환 - 고객의 소득 : 로그변환
            - 범주화 - 각 범주의 빈도가 비슷하게 되도록 설정
        - 범주형 변수의 경우 가변수화하여 적용하고 가능하면 모든 범주형 변수는 같은 범위를 갖도록 가변수화 하는 것이 좋음
    - 가중치의 초기값과 다중 최소값 문제
        - 역전파 알고리즘은 초기값에 따라 결과가 많이 달라지므로 초기값의 선택은 매우 중요한 문제임
        - 가중치가 0이면 시그모이드 함수는 선형이 되고 신경망 모형은 근사적으로 선형모형이 된다
        - 일반적으로 초기값은 - 근처로 랜덤하게 선택하므로 초기 모형은 선형모형에 가깝고, 가중치 값이 증가할수록 비선형모형이 된다
    - 학습모드
        - 온라인 학습 모드
            - 각 관측값을 순차적으로 하나씩 신경망에 투입하여 가중치 추정값이 매번 바뀐다
            - 일반적으로 속도가 빠르며, 특히 훈련자료에 유사값이 많은 경우 그 차이가 더 두드러진다
            - 훈련자료가 비정상성과 같이 특이한 성질을 가진 경우가 좋다
            - 국소최솟값에서 벗어나기가 더 쉽다
        - 확률적 학습 모드
            - 온라인 학습 모드와 같으나 신경망에 투입되는 관측값의 순서가 랜덤함
        - 배치 학습 모드
            - 전체 훈련자료를 동시에 신경망에 투입함
    - 은닉층과 은닉노드의 수
        - 신경망을 적용할 때 가장 중요한 부분이 모형의 선택임
        - 은닉층고가 은닉노드가 많으면 가중치가 많아져서 과대 적합 문제가 발생한다
        - 은닉층과 은닉노드가 적으면 과소적합 문제가 발생한다
        - 은닉층의 수가 하나인 신경망은 범용 근사자이므로 모든 매끄러운 함수를 근사적으로 표현할 수 있다. 그러므로 가능하면 은닉층은 하나로 선정한다.
        - 은닉노드의 수는 적절히 큰 값으로 놓고 가중치를 감소시키며 적용하는 것이 좋다.
    - 과대 적합 문제
        - 신경망에서는 많은 가중치를 추정해야 하므로 과대적합 문제가 빈번하다
        - 알고리즘의 조기종료와 가중치 감소 기법으로 해결할 수 있다
        - 모형이 적합하는 과정에서 검증오차가 증가하기 시작하면 반복을 중지하는 조기종료를 시행
        - 선형모형의 능형회귀와 유사한 가중치 감소라는 벌점화 기법을 활용함

### 군집분석

- 군집분석
    - 각 객체의 유사성을 측정하여 유사성이 높은 대상 집단을 분류하고, 군집에 속한 객체들의 유사성과 서로 다른 군집에 속한 객체간의 상이성을 규명하는 분석 방법
    - 특성에 따라 고객을 여러 개의 배타적인 집단으로 나누는 것
    - 결과는 구체적인 군집분석 방법에 따라 차이가 나타날 수 있음
    - 군집의 개수나 구조에 대한 가정 없이 데이터들 사이의 거리를 기준으로 군집화를 유도
    - 마케팅 조사에서 소비자들의 상품구매행동이나 life style에 따른 소비자군을 분류하여 시장 전략 수집 등에 활용
    - 특징
        - 요인분석과의 차이점 - 요인분석은 유사한 변수를 함께 묶어주는 것이 목적
        - 판별분석과의 차이점 - 판별분석은 사전에 집단이 나누어져 있는 자료를 통해 새로운 데이터를 기존의 집단에 할당하는 것이 목적
- 거리
    - 군집분석에서는 관측 데이터 간 유사성이나 근접성을 측정해 어느 군집으로 묶을 수 있는지 판단해야 함
    - 연속형 변수
        - 유클리디안 거리
            - 데이터간의 유사성을 측정할 때 많이 사용하는 거리
            - 통계적 개념이 내포되어 있지 않아 변수들의 산포 정도가 전혀 감안되어 있지 않음
        - 표준화 거리
            - 해당변수의 표준편차로 척도 변환한 후 유클리드안 거리를 계산하는 방법
            - 표준화 하게 되면 척도의 차이, 분산의 차이로 인한 왜곡을 피할 수 있다
        - 마할라노비스 거리
            - 통계적 개념이 포함된 거리이며 변수들의 산포를 고려하여 이를 표준화한 거리
            - 두 벡터 사이의 거리를 산포를 의미하는 표본공분산으로 나눠주어야 하며, 그룹에 대한 사전 지식 없이는 표본 공분산S를 계산할 수 없으므로 사용하기 곤란함
        - 체비셰프 거리
        - 맨하탄 거리
            - 유클리디안 거리와 함께 가장 많이 사용되는 거리
            - 맨하탄 도시에서 건물에서 건물을 가기 위한 최단 거리를 구하기 위해 고안된 거리
        - 캔버라 거리
        - 민코우스키 거리
            - 맨하탄 거리와 유클리디안 거리를 한번에 표현한 공식으로 L1 거리(맨하탄거리), L2 거리(유클리디안 거리)라 불리고 있다
    - 범주형 변수
        - 자카드거리
        - 자카드 계수
        - 코사인 거리
            - 문서를 유사도를 기준으로 분류 혹은 그룹핑 할 때 유용하게 사용한다
        - 코사인 유사도
            - 두 개체의 백터 내적의 코사인 값을 이용하여 측정된 벡터간의 유사한 정도
- 계층적 군집분석
    - 계층적 군집방법은 n개의 군집으로 시작해 점차 군집의 개수를 줄여 나가는 방법
    - 계층적 군집을 형성하는 방법에는 합병형 방법과 분리형 방법이 있다
    - 최단연결법
        - n*n거리 행렬에서 거리가 가장 가까운 데이터를 묶어서 군집을 형성
        - 군집과 군집 또는 데이터와의 거리를 계산 시 최단거리를 거리로 계산하여 거리행렬 수정을 진행
        - 수정된 거리행렬에서 거리가 가까운 데이터 또는 군집을 새로운 군집으로 형성
    - 최장연결법
        - 군집과 군집 또는 데이터와의 거래를 계산할 때 최장거리를 거리로 계산하여 거리행렬을 수정하는 방법
    - 평균연결법
        - 군집과 군집 또는 데이터와의 거래를 계싼할 때 평균을 거리로 계산하여 거리행렬을 수정하는 방법
    - 와드연결법
        - 군집내 편차들의 제곱합을 고려한 방법
        - 군집 간 정보의 손실을 최소화하기 위해 군집화를 진행
    - 군집화
        - 거리행렬을 통해 가장 가까운 거리의 객체들간의 관계를 규명하고 덴드로그램을 그린다
        - 덴드로그램을 보고 군집의 개수를 변화해 가면서 적절한 군집 수를 선정한다
        - 군집의 수는 분석 목적에 따라 선정할 수 있지만 대부분 5개 이상의 군집은 잘 활용하지 않는다
        - 군집화 단계
            1. 거리행렬을 기준으로 덴드로그램을 그린다
            2. 덴드로그램의 최상단부터 세로축의 개수에 따라 가로선을 그어 군집의 개수를 선택한다
            3. 각 객체들의 구성을 고려해서 적절한 군집수를 선정한다
- 비계층적 군집분석
    - n개의 개체를 g개의 군집으로 나눌 수 있는 모든 가능한 방법을 점검해 최적화한 군집을 형성하는 것
    - K-평균 군집분석(k-means clustering)의 개념
        - 주어진 데이터를 k개의 클러스터로 묶는 알고리즘으로, 각 클러스터와 거리 차이의 분산을 최소화하는 방식으로 동작
    - K-평균 군집분석 과정
        1. 원하는 군집의 개수와 초기 값들을 정해 seed 중심으로 군집을 형성
        2. 각 데이터를 거리가 가장 가까운 seed가 있는 군집으로 분류
        3. 각 군집의 seed 값을 다시 계산
        4. 모든 개체가 군집으로 할당될 때까지 위 과정들을 반복
    - K-평균 군집분석의 특징
        - 거리 계산을 통해 군집화가 이루어지므로 연속형 변수에 활용이 가능
        - K개의 초기 중심값은 임의로 선택이 가능, 가급적이면 멀리 떨어지는 것이 바람직
        - 초기 중심값을 임의로 선택할 때 일렬로 선택하면 군집 혼합되지 않고 층으로 나누어질 수 있어 주의해야 함. 초기 중심값의 선정에 따라 결과가 달라질 수 있다
        - 초기 중심으로부터의 오차 제곱합을 최소화하는 방향으로 군집이 형성되는 탐욕적(greedy)알고리즘이므로 안정된 군집은 보장하나 최적이라는 보장은 없다
        - 장점
            - 알고리즘이 단순하며 빠르게 수행되어 분석 방법 적용이 용이함
            - 계층적 군집분석에 비해 많은 양의 데이터를 다룰 수 있따
            - 내부 구조에 대한 사전정보가 없어도 의미있는 자료구조를 찾을 수 있다
            - 다양한 형태의 데이터에 적용이 가능하다
        - 단점
            - 군집의 수, 가중치와 거리 정의가 어렵다
            - 사전에 주어진 목적이 없으므로 결과 해석이 어렵다
            - 잡음이나 이상값의 영향을 많이 받는다
            - 볼록한 형태가 아닌 군집이 존재할 경우에는 성능이 떨어진다
            - 초기 군집수 결정에 어려움이 있다
- 혼합 군집분석
    - 모형 기반의 군집 방법
    - 데이터가 k개의 보수적 모형의 가중합으로 표현되는 모집단 모형으로부터 나왔다는 가정하에서 모수와 함께 가중치를 자료로부터 추정하는 방법을 사용
    - K개의 각 모형은 군집을 의미하며, 각 데이터는 추정된 k개의 모형 중 어느 모형으로부터 나왔을 확률이 높은지에 따라 군집의 분류가 이루어진다
    - 흔히 혼합모형에서의 모수와 가중치의 추정에는 EM 알고리즘이 사용된다
    - 혼합 분포 모형으로 설명할 수 있는 데이터의 형태
        - 다봉형의 형태 - 단일분포로의 적합을 적절하지 않으며 대략 3개 정도의 정규분포 결합을 통해 설명될 수 있을 것
    - EM 알고리즘의 진행 과정
        - 각 자료에 대해 Z의 조건부분포로부터 조건부 기댓값을 구할 수 있다
        - 관측변수 X와 잠재변수 Z를 포함하는 (X, Z)에 대한 로그 - 가능도함수에 Z 대신 상수값인 Z의 조건부 기댓값을 대입하면, 로그-가능도함수를 최대로 하는 모수를 쉽게 찾을 수 있다. (M-단계 ) 갱신된 모수 추정치에 대해 위 과정을 반복한다면 수렴하는 값을 얻게 되고, 이는 최대 가능도 추정치로 사용될 수 있다
        - E - 단계 : 잠재변수 Z의 기대치 계산
        - M - 단계 : 잠재변수 Z의 기대치를 이용하여 파라미터를 추정
    - 혼합 분포 군집모형의 특징
        - K - 평균군집의 절차와 유사하지만 확률분포를 도입하여 군집을 수행
        - 군집을 몇 개의 모수로 표현할 수 있으며, 서로 다른 크기나 모양의 군집을 찾을 수 있다
        - EM 알고리즘을 이용한 모수 추정에서 데이터가 커지면 수렴에 시간이 걸릴 수 있다
        - 군집의 크기가 너무 작으면 추정의 정도가 떨어지거나 어려울 수 있다
        - K-평균군집과 같이 이상치 자료에 민감하므로 사전에 조치가 필요
- SOM(Self Organizing Map)
    - 자가조직화지도 알고리즘은 코호넨에 의해 제시, 개발 (코호넨 맵으로 알려져있음)
    - 비지도 신경망으로 고차원의 데이터를 이해하기 쉬운 저차원의 뉴런으로 정렬하여 지도의 형태로 형상화
    - 실제 공간의 입력 변수가 가까이 있으면, 지도상에도 가까운 위치에 있게 됨
    - 구성
        1. 입력층
            - 입력변수의 개수와 동일하게 뉴런 수가 존재
        2. 경쟁층 
- 최신 군집분석 기법들

### 연관분석

- 연관규칙
- 기존 연관성분석의 이슈
- 최근 연관성분석 동향
- 연관성분석 활용방안
- 연관성분석 예제
-